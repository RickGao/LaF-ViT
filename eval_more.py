import argparse
import torch
import torch.utils.data
from torch.utils.data import DataLoader, random_split
from dataset import UTKFaceDataset, val_transforms
from model import LaFViT
import numpy as np
import random
import sys

# ==========================================
# å‘½ä»¤è¡Œå‚æ•°
# ==========================================
parser = argparse.ArgumentParser()
parser.add_argument('--data_dir', type=str, default='./data/UTKFace')
parser.add_argument('--model_path', type=str, required=True, help='Checkpointè·¯å¾„')
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--seed', type=int, default=42, help='å¿…é¡»å’Œè®­ç»ƒæ—¶ä¿æŒä¸€è‡´')
parser.add_argument('--val_percent', type=int, default=10, help='éªŒè¯é›†æ¯”ä¾‹')
parser.add_argument('--use_hard', action='store_true', help='å¼€å¯ Hard Conditioning æ¨¡å¼ (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)')
args = parser.parse_args()


def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def print_row(name, count, mae, std, g_acc, r_acc):
    """è¾…åŠ©å‡½æ•°ï¼šæ‰“å°è¡¨æ ¼çš„ä¸€è¡Œ"""
    print(f"{name:<20} | {count:<8} | {mae:<10.4f} | {std:<8.2f} | {g_acc:<9.1f}% | {r_acc:<9.1f}%")


def analyze_metrics(data_dict, category_name):
    """
    è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—å¹¶æ‰“å°æŸä¸€ç±»çš„ç»Ÿè®¡æ•°æ®
    è¿”å›è¯¥ç±»çš„ (mae, g_acc, r_acc) ç”¨äºåŠ æƒå¹³å‡
    """
    if len(data_dict['age_errs']) == 0:
        return None

    mae = np.mean(data_dict['age_errs'])
    std = np.std(data_dict['age_errs'])
    g_acc = np.mean(data_dict['gender_hits']) * 100
    r_acc = np.mean(data_dict['race_hits']) * 100
    count = len(data_dict['age_errs'])

    print_row(category_name, count, mae, std, g_acc, r_acc)
    return mae


def main():
    set_seed(args.seed)
    device = torch.device(
        "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    print(f"ğŸš€ Evaluation | Device: {device} | Seed: {args.seed}")

    # 1. åŠ è½½æ¨¡å‹
    print(f"ğŸ“‚ Loading model: {args.model_path}")
    # æ³¨æ„ï¼šç¡®ä¿ use_hard_conditioning å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´
    model = LaFViT(pretrained=False, use_hard_conditioning=args.use_hard)
    model.load_state_dict(torch.load(args.model_path, map_location=device))
    model.to(device)
    model.eval()

    # 2. æ„å»ºæ•°æ®é›†
    full_dataset = UTKFaceDataset(args.data_dir, transform=val_transforms)
    total_len = len(full_dataset)

    if args.val_percent > 0:
        train_len = int(total_len * (100 - args.val_percent) / 100)
        val_len = total_len - train_len
        gen = torch.Generator().manual_seed(args.seed)
        _, val_subset = random_split(full_dataset, [train_len, val_len], generator=gen)
        print(f"âš ï¸ Mode: Validation Set Only ({args.val_percent}%)")
        dataset = val_subset
    else:
        print("âš ï¸ Mode: Full Dataset")
        dataset = full_dataset

    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)

    # ==========================================
    # 3. åˆå§‹åŒ–æ•°æ®å®¹å™¨
    # ==========================================
    # ç»“æ„: metrics[key] = {'age_errs': [], 'gender_hits': [], 'race_hits': []}

    # æŒ‰ç§æ— (0-4)
    race_metrics = {r: {'age_errs': [], 'gender_hits': [], 'race_hits': []} for r in range(5)}
    # æŒ‰æ€§åˆ« (0:Male, 1:Female)
    gender_metrics = {g: {'age_errs': [], 'gender_hits': [], 'race_hits': []} for g in range(2)}
    # æŒ‰ç»„åˆ (Race_idx * 2 + Gender_idx) -> æ¯”å¦‚ 0=WhiteMale, 1=WhiteFemale
    combo_metrics = {k: {'age_errs': [], 'gender_hits': [], 'race_hits': []} for k in range(10)}
    # æ•´ä½“
    overall_metrics = {'age_errs': [], 'gender_hits': [], 'race_hits': []}

    print("Starting evaluation...")

    # ==========================================
    # 4. æ¨ç†å¾ªç¯
    # ==========================================
    with torch.no_grad():
        for batch in tqdm(loader, desc="Evaluating", file=sys.stdout):
            imgs = batch['image'].to(device)
            ages_true = batch['age'].to(device).view(-1, 1)
            genders_true = batch['gender'].to(device)
            races_true = batch['race'].to(device)

            # --- Forward ---
            age_pred, gender_logits, race_logits = model(imgs, stage="stage2")

            # --- è¿˜åŸçœŸå®å¹´é¾„ ---
            age_pred_real = age_pred * 100.0

            # --- è®¡ç®—è¯¯å·® ---
            abs_errs = torch.abs(age_pred_real - ages_true).cpu().numpy()
            gender_hits = (torch.argmax(gender_logits, 1) == genders_true).cpu().numpy()
            race_hits = (torch.argmax(race_logits, 1) == races_true).cpu().numpy()

            # è½¬ CPU ä»¥ä¾¿ç´¢å¼•
            g_cpu = genders_true.cpu().numpy()
            r_cpu = races_true.cpu().numpy()

            # --- å¡«å…¥å®¹å™¨ ---
            for i in range(len(imgs)):
                r = int(r_cpu[i])
                g = int(g_cpu[i])
                combo_key = r * 2 + g  # 0~9 çš„å”¯ä¸€ç´¢å¼•

                err = abs_errs[i][0]
                gh = int(gender_hits[i])
                rh = int(race_hits[i])

                # 1. Race
                race_metrics[r]['age_errs'].append(err)
                race_metrics[r]['gender_hits'].append(gh)
                race_metrics[r]['race_hits'].append(rh)

                # 2. Gender
                gender_metrics[g]['age_errs'].append(err)
                gender_metrics[g]['gender_hits'].append(gh)
                gender_metrics[g]['race_hits'].append(rh)

                # 3. Combo
                combo_metrics[combo_key]['age_errs'].append(err)
                combo_metrics[combo_key]['gender_hits'].append(gh)
                combo_metrics[combo_key]['race_hits'].append(rh)

                # 4. Overall
                overall_metrics['age_errs'].append(err)
                overall_metrics['gender_hits'].append(gh)
                overall_metrics['race_hits'].append(rh)

    # ==========================================
    # 5. æ‰“å°å®Œæ•´æŠ¥å‘Š
    # ==========================================
    race_names = ["White", "Black", "Asian", "Indian", "Others"]
    gender_names = ["Male", "Female"]

    print("\n" + "=" * 90)
    print(f"{'COMPREHENSIVE FAIRNESS REPORT':^90}")
    print("=" * 90)
    print(f"{'Group':<20} | {'Count':<8} | {'Age MAE':<10} | {'Std':<8} | {'Gen Acc':<10} | {'Race Acc':<10}")
    print("-" * 90)

    # --- Section 1: æŒ‰æ€§åˆ« ---
    print(f" >>> BY GENDER")
    for g in range(2):
        analyze_metrics(gender_metrics[g], gender_names[g])
    print("-" * 90)

    # --- Section 2: æŒ‰ç§æ— ---
    print(f" >>> BY RACE")
    for r in range(5):
        analyze_metrics(race_metrics[r], race_names[r])
    print("-" * 90)

    # --- Section 3: äº¤å‰ç»„åˆ (æœ€è¯¦ç»†) ---
    print(f" >>> BY SUBGROUP (Race + Gender)")
    for r in range(5):
        for g in range(2):
            combo_key = r * 2 + g
            name = f"{race_names[r]}-{gender_names[g]}"
            analyze_metrics(combo_metrics[combo_key], name)

    # --- Section 4: æ€»ä½“ ---
    print("=" * 90)
    if len(overall_metrics['age_errs']) > 0:
        analyze_metrics(overall_metrics, "OVERALL")
    print("=" * 90)


# éœ€è¦åŠ ä¸ª tqdm æ–¹ä¾¿çœ‹è¿›åº¦ï¼Œå¦‚æœæ²¡æœ‰è£… tqdm å¯ä»¥åˆ æ‰
try:
    from tqdm import tqdm
except ImportError:
    def tqdm(iterable, **kwargs):
        return iterable

if __name__ == "__main__":
    main()