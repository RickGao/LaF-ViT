import argparse
import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torch.optim.lr_scheduler import CosineAnnealingLR
from dataset import UTKFaceDataset, train_transforms, val_transforms
from model import LaFViT
from tqdm import tqdm
import logging
import sys
from datetime import datetime

# ==========================================
# 1. å‘½ä»¤è¡Œå‚æ•°é…ç½®
# ==========================================
parser = argparse.ArgumentParser(description='LaFViT Training (Weighted + Norm + DiffLR)')
parser.add_argument('--data_dir', type=str, default='./data/UTKFace', help='æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„')
parser.add_argument('--epochs', type=int, default=30, help='è®­ç»ƒæ€»è½®æ•°')
parser.add_argument('--batch_size', type=int, default=64, help='Batch Size')
parser.add_argument('--lr', type=float, default=1e-4, help='Stage 1 çš„åˆå§‹å­¦ä¹ ç‡')
parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
parser.add_argument('--save_dir', type=str, default='./checkpoints', help='æ¨¡å‹ä¿å­˜è·¯å¾„')
args = parser.parse_args()


# ==========================================
# 2. è¾…åŠ©å‡½æ•°
# ==========================================
def setup_logger(log_dir):
    """é…ç½® Loggerï¼Œæ–‡ä»¶åå¸¦æ—¶é—´æˆ³"""
    os.makedirs(log_dir, exist_ok=True)
    current_time = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_filename = f'train_log_{current_time}.txt'
    log_path = os.path.join(log_dir, log_filename)

    logger = logging.getLogger("LaFViT")
    logger.setLevel(logging.INFO)

    if logger.hasHandlers():
        logger.handlers.clear()

    formatter = logging.Formatter('%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

    file_handler = logging.FileHandler(log_path)
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    return logger, log_path


def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True


def validate(model, loader, device, stage):
    model.eval()
    total_mae, correct_gen, correct_race, count = 0, 0, 0, 0
    with torch.no_grad():
        for batch in loader:
            imgs = batch['image'].to(device)
            ages = batch['age'].to(device).view(-1, 1)
            genders = batch['gender'].to(device)
            races = batch['race'].to(device)

            age_pred, g_logits, r_logits = model(imgs, stage=stage)

            count += len(imgs)
            correct_gen += (torch.argmax(g_logits, 1) == genders).sum().item()
            correct_race += (torch.argmax(r_logits, 1) == races).sum().item()

            if stage == "stage2":
                # ğŸ”¥ã€æ”¹åŠ¨ç‚¹Aã€‘: éªŒè¯æ—¶éœ€è¦è¿˜åŸå¹´é¾„
                # æ¨¡å‹è¾“å‡ºæ˜¯ 0.3 -> è¿˜åŸæˆ 30 å²
                pred_age_real = age_pred * 100.0
                total_mae += torch.sum(torch.abs(pred_age_real - ages)).item()
            else:
                total_mae = 99.9
    return (total_mae / count), (correct_gen / count), (correct_race / count)


# ==========================================
# 3. ä¸»ç¨‹åº
# ==========================================
def main():
    # --- Step A: è®¾ç½®ç¯å¢ƒ ---
    log_dir = './log'
    ckpt_dir = args.save_dir
    os.makedirs(ckpt_dir, exist_ok=True)

    logger, log_path = setup_logger(log_dir)
    set_seed(args.seed)
    device = torch.device(
        "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")

    stage1_epochs = int(args.epochs * 0.2)
    stage2_epochs = args.epochs - stage1_epochs

    logger.info("=" * 40)
    logger.info(f"ğŸš€ Training LaFViT | Device: {device} | Seed: {args.seed}")
    logger.info(f"ğŸ“‚ Log saved to: {log_path}")
    logger.info(f"âš™ï¸ Config: Epochs={args.epochs} (S1={stage1_epochs}, S2={stage2_epochs})")
    logger.info(f"âœ¨ Enhancements: RaceWeights(1,1,1,2,3), AgeNorm(/100), DiffLR(x4)")
    logger.info("=" * 40)

    # --- Step B: æ•°æ®é›†åŠ è½½ ---
    gen = torch.Generator().manual_seed(args.seed)
    temp_ds = UTKFaceDataset(args.data_dir, transform=None)
    train_len = int(0.9 * len(temp_ds))
    val_len = len(temp_ds) - train_len

    train_ds_full = UTKFaceDataset(args.data_dir, transform=train_transforms)
    val_ds_full = UTKFaceDataset(args.data_dir, transform=val_transforms)

    train_subset, _ = random_split(train_ds_full, [train_len, val_len], generator=gen)
    _, val_subset = random_split(val_ds_full, [train_len, val_len], generator=gen)

    train_loader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False, num_workers=2)

    logger.info(f"ğŸ“Š Dataset Split: Train={len(train_subset)}, Val={len(val_subset)}")

    # --- Step C: æ¨¡å‹åˆå§‹åŒ– ---
    logger.info("ğŸ§  Initializing LaFViT (Small + Base)...")
    model = LaFViT(pretrained=True).to(device)

    # ==========================================
    # ğŸ”¥ã€æ”¹åŠ¨ç‚¹Bã€‘: Loss é…ç½®
    # ==========================================
    criterion_age = nn.MSELoss()
    criterion_gender = nn.CrossEntropyLoss()

    # Race Class Weights: 0:White, 1:Black, 2:Asian, 3:Indian, 4:Others
    # ç­–ç•¥: White/Black/Asian=1.0, Indian=2.0, Others=3.0
    race_weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 3.0]).to(device)
    criterion_race = nn.CrossEntropyLoss(weight=race_weights)

    # åˆå§‹ä¼˜åŒ–å™¨ (Stage 1)
    optimizer = optim.AdamW([
        {'params': model.demo_backbone.parameters()},
        {'params': model.gender_head.parameters()},
        {'params': model.race_head.parameters()}
    ], lr=args.lr)

    scheduler = None
    best_val_mae = float('inf')

    # --- Step D: è®­ç»ƒå¾ªç¯ ---
    logger.info("ğŸ”¥ Start Training Loop...")

    for epoch in range(args.epochs):
        model.train()
        total_loss = 0

        # --- é˜¶æ®µåˆ‡æ¢é€»è¾‘ ---
        if epoch < stage1_epochs:
            stage = "stage1"
            # å†»ç»“ Base, æ¿€æ´» Small
            for p in model.age_backbone.parameters(): p.requires_grad = False
            for p in model.age_head.parameters(): p.requires_grad = False
            for p in model.demo_backbone.parameters(): p.requires_grad = True

        elif epoch == stage1_epochs:
            logger.info("ğŸ§Š Switch to Stage 2: Freezing Small, Training Base...")
            stage = "stage2"

            # å¼ºåˆ¶ Small è¿›å…¥ eval æ¨¡å¼ï¼Œé˜²æ­¢ BN ç»Ÿè®¡æ¼‚ç§»
            model.demo_backbone.eval()
            model.gender_head.eval()
            model.race_head.eval()

            # å†»ç»“ Small
            for p in model.demo_backbone.parameters(): p.requires_grad = False
            for p in model.gender_head.parameters(): p.requires_grad = False
            for p in model.race_head.parameters(): p.requires_grad = False

            # è§£å†» Base
            for p in model.age_backbone.parameters(): p.requires_grad = True
            for p in model.age_head.parameters(): p.requires_grad = True

            optimizer = optim.AdamW([
                # Backbone: 1e-5
                {'params': model.age_backbone.parameters(), 'lr': 1e-5},
                # Head: 4e-5
                {'params': model.age_head.parameters(), 'lr': 4e-5}
            ], weight_decay=0.05)  # <--- ä» 1e-2 æ”¹æˆ 0.05ï¼Œå¢å¼ºçº¦æŸ

            scheduler = CosineAnnealingLR(optimizer, T_max=stage2_epochs, eta_min=1e-6)
        else:
            stage = "stage2"
            # ä¿æŒ Small ä¸º eval æ¨¡å¼
            model.demo_backbone.eval()
            model.gender_head.eval()
            model.race_head.eval()

        # --- Tqdm å¾ªç¯ ---
        loop = tqdm(train_loader, desc=f"Ep {epoch + 1}/{args.epochs} [{stage}]")

        for batch in loop:
            imgs = batch['image'].to(device)
            ages = batch['age'].to(device).view(-1, 1)
            genders = batch['gender'].to(device)
            races = batch['race'].to(device)

            # ==========================================
            # ğŸ”¥ã€æ”¹åŠ¨ç‚¹Dã€‘: å¹´é¾„å½’ä¸€åŒ– (Age Normalization)
            # ==========================================
            if stage == "stage2":
                ages_target = ages / 100.0  # [0, 100] -> [0.0, 1.0]
            else:
                ages_target = ages  # stage1 ä¸ç”¨ ageï¼Œæ— æ‰€è°“

            optimizer.zero_grad()
            age_pred, g_logits, r_logits = model(imgs, stage=stage)

            if stage == "stage1":
                # åˆ†ç±»ä»»åŠ¡: åŒ…å«äº†åŠ æƒçš„ Race Loss
                loss = criterion_gender(g_logits, genders) + criterion_race(r_logits, races)
                d_val = 0.0
            else:
                # å›å½’ä»»åŠ¡: æ‹Ÿåˆå½’ä¸€åŒ–åçš„å¹´é¾„
                loss = criterion_age(age_pred, ages_target)
                d_val = loss.item()

            loss.backward()
            optimizer.step()
            total_loss += loss.item()

            # è¿›åº¦æ¡æ˜¾ç¤º
            with torch.no_grad():
                acc_g = (torch.argmax(g_logits, 1) == genders).float().mean()
                acc_r = (torch.argmax(r_logits, 1) == races).float().mean()
            loop.set_postfix(loss=loss.item(), mse=d_val, g=f"{acc_g:.2f}", r=f"{acc_r:.2f}")

        if scheduler: scheduler.step()

        # --- éªŒè¯ä¸æ—¥å¿— ---
        val_mae, val_gen, val_race = validate(model, val_loader, device, stage)
        avg_train_loss = total_loss / len(train_loader)

        logger.info(
            f"Epoch {epoch + 1:02d} Report | Train Loss: {avg_train_loss:.4f} | Val MAE: {val_mae:.4f} | Gen Acc: {val_gen:.2%} | Race Acc: {val_race:.2%}")

        # --- ä¿å­˜ ---
        torch.save(model.state_dict(), os.path.join(ckpt_dir, 'laf_vit_latest.pth'))

        if stage == "stage2" and val_mae < best_val_mae:
            best_val_mae = val_mae
            torch.save(model.state_dict(), os.path.join(ckpt_dir, 'laf_vit_best.pth'))
            logger.info(f"  ğŸŒŸ New Best Model Saved! (MAE: {best_val_mae:.4f})")

        if (epoch + 1) % 2 == 0:
            ckpt_name = f'laf_vit_epoch_{epoch + 1}.pth'
            torch.save(model.state_dict(), os.path.join(ckpt_dir, ckpt_name))

    logger.info("ğŸ‰ Training Complete.")


if __name__ == "__main__":
    main()